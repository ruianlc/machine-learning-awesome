{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-5-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.分位数计算："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "  \n",
    "# 1D array \n",
    "arr = [20, 2, 7, 1, 34,5,24,18,50,68,3,78,105,142,320,298,398,245,321,256]\n",
    "\n",
    "quantiles = np.arange(0.1, 0.99 + 1e-6, 0.1)  # 分位数范围\n",
    "\n",
    "arr_n = np.quantile(arr,q=quantiles)\n",
    "\n",
    "print(\"arr_n : \", arr_n) \n",
    "# print(\"Q2 quantile of arr : \", arr.quant.quantile(arr, .50))\n",
    "# print(\"Q1 quantile of arr : \", np.quantile(arr, .25))\n",
    "# print(\"Q3 quantile of arr : \", np.quantile(arr, .75))\n",
    "# print(\"100th quantile of arr : \", np.quantile(arr, .1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-5-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.数组拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "a = np.array([[1,1,1],[2,2,2]])\n",
    "b = 2 * np.array([[1,1,1],[2,2,2]])\n",
    "c = np.array([[3,3,3]])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "k = np.append(a,b,axis=0) # 按行数组拼接\n",
    "m = np.append(a,c,axis=0)\n",
    "\n",
    "d = c.reshape(1,-1)  # 一个类别的单个样本\n",
    "h = np.append(a,d,axis=0)\n",
    "\n",
    "n = np.average(k, axis=0) # 按列求均值\n",
    "\n",
    "print(\"k is:\",k)\n",
    "print(\"m is:\",m)\n",
    "print(\"n is:\",n)\n",
    "print(\"h is:\",h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 多宽度模拟切丝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_width_list = []\n",
    "for k in range(19,30):\n",
    "    cut_width_list.append( round(k / 24, 3))\n",
    "cut_width_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.模型超参优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "mdl = XGBClassifier(objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "    # RandomizedSearchCV\n",
    "    search_spaces = dict(\n",
    "        learning_rate=[0.1, 0.01, 0.05],\n",
    "        n_estimators=range(200, 700, 100),\n",
    "        min_child_weight=[1, 5, 10],\n",
    "        gamma=[0.5, 1, 1.5, 2, 5],\n",
    "        subsample=[0.6, 0.8, 1.0],\n",
    "        colsample_bytree=[0.6, 0.8, 1.0],\n",
    "        max_depth=range(2, 10, 1),\n",
    "    )\n",
    "\n",
    "    searchcv = RandomizedSearchCV(\n",
    "        mdl,\n",
    "        param_distributions=search_spaces,\n",
    "        cv=mdl_cv_kf,\n",
    "        scoring=mdl_scoring_acc,\n",
    "        verbose=0,\n",
    "        refit=False,\n",
    "        n_jobs=-1,\n",
    "        n_iter=20,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.图标签替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# We need to draw the canvas, otherwise the labels won't be positioned and \n",
    "# won't have values yet.\n",
    "fig.canvas.draw()\n",
    "\n",
    "labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "labels[1] = 'Testing'\n",
    "\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际项目表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.canvas.draw()\n",
    "target_counts.plot(kind='bar', title='Count (target)')\n",
    "code_labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "text_labels = [sim_level_map[int(item)] for item in code_labels]\n",
    "ax.set_xticklabels(text_labels, rotation = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. range测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(1, 3)\n",
    "print(a)\n",
    "print(list(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，range返回一个list。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(5)\n",
    "print(list(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若不设定起始值，则range范围默认起始值为0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Series循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "s = pd.Series(['A', 'B', 'C'])\n",
    "for index, value in s.items():\n",
    "    print(f\"Index : {index}, Value : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ExtraTree Feature Imporrtance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(10), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(10), indices)\n",
    "plt.xlim([-1, 10])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. The network graph to visualization correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import networkx as nx\n",
    "from ipywidgets import Layout, widgets\n",
    "import math\n",
    "import matplotlib.dates as md\n",
    "import yfinance as yf\n",
    "\n",
    "\n",
    "payload = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "\n",
    "\n",
    "# S&P500 metadata\n",
    "sp500_table = payload[0]\n",
    "\n",
    "# mappings \n",
    "sp500_tickers = sp500_table.Symbol.str.upper().values\n",
    "sp500_names = sp500_table.Security.values\n",
    "sp500_sectors = sp500_table[\"GICS Sector\"].values\n",
    "sp500_sub_sectors = sp500_table[\"GICS Sub-Industry\"].values\n",
    "sp500_names_mapping = dict(zip(sp500_tickers, sp500_names))\n",
    "sp500_sector_mapping = dict(zip(sp500_names, sp500_sectors))\n",
    "sp500_sub_sector_mapping = dict(zip(sp500_names, sp500_sub_sectors))\n",
    "sector_color_mapping = dict(zip(sp500_sectors, sns.color_palette(\"pastel\", len(sp500_sectors)).as_hex()))\n",
    "subsector_color_mapping = dict(zip(sp500_sub_sectors, sns.color_palette(\"pastel\", len(sp500_sub_sectors)).as_hex()))\n",
    "\n",
    "# download S&P500 financial data\n",
    "tickers = list(sp500_tickers)\n",
    "prices = yf.download(tickers, start=\"2020-01-01\", end=\"2021-12-31\", interval='1d')\n",
    "prices = prices[\"Adj Close\"]\n",
    "prices = prices.rename(columns=sp500_names_mapping)\n",
    "prices\n",
    "\n",
    "# impute\n",
    "for i, row in prices.iterrows():\n",
    "  if row.isnull().mean() > 0.9: prices.drop(i, inplace=True)\n",
    "prices = prices.loc[:, prices.isnull().mean() < 0.3]\n",
    "prices = prices.fillna(method='bfill')\n",
    "print(prices.shape)\n",
    "\n",
    "# calculate rolling correlation\n",
    "corr = prices.rolling(60).corr()\n",
    "corr_ = np.array([corr.loc[i].to_numpy() for i in prices.index if not np.isnan(corr.loc[i].to_numpy()).all()])\n",
    "corr_ = np.nansum(corr_, axis=0)/len(corr_)\n",
    "corr_ = pd.DataFrame(columns=prices.columns.tolist(), index=prices.columns.tolist(), data=corr_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_choice = widgets.FloatSlider(description=\"Threshold\", value=0.8, min=0.5, max=1, step=0.05, continuous_update=False, \n",
    "                                       orientation='horizontal', layout=Layout(width='500px'), style=dict(description_width= 'initial'))\n",
    "network = go.FigureWidget(data=[go.Scatter(x=[], y=[], mode='lines', text=[],  line=dict(color='MediumPurple', width=10), marker=dict(size=20, line_width=10,line=dict(color='MediumPurple',width=2))),\n",
    "                                 go.Scatter(x=[], y=[],mode='markers+text', textposition=\"top center\", text=[],hoverinfo='text',textfont_size=12, marker=dict(size=50, color=[],line_width=1))],\n",
    "                          layout=go.Layout( showlegend=False, annotations=[], margin=dict(t=40, b=0, l=0, r=0), width=1600, height=800))\n",
    "df = prices.copy()\n",
    "correlation_matrix = corr_.to_numpy()\n",
    "\n",
    "def plot_corr_graph(change):\n",
    "    threshold, corr_mode = None, None\n",
    "    threshold = change.new\n",
    "    \n",
    "    tr_ind = np.triu_indices(correlation_matrix.shape[0])\n",
    "    correlation_matrix[tr_ind] = 0\n",
    "    G = nx.from_numpy_matrix(correlation_matrix)\n",
    "    G = nx.relabel_nodes(G, lambda x: df.columns.tolist()[x])\n",
    "    # 49 x 49 - 49 (self corr) / 2 (remove upper triang)\n",
    "    remove = []\n",
    "    \n",
    "    for col1, col2, weight in G.edges(data=True):\n",
    "      if math.isnan(weight[\"weight\"]):\n",
    "        remove.append((col1,col2))\n",
    "    \n",
    "      if abs(weight[\"weight\"]) < threshold:\n",
    "        remove.append((col1,col2))\n",
    "    \n",
    "    G.remove_edges_from(remove)\n",
    "    \n",
    "    remove = []\n",
    "    edges = list(sum(G.edges, ()))\n",
    "    \n",
    "    for node in G.nodes:\n",
    "      if node not in edges:\n",
    "        remove.append(node)\n",
    "    G.remove_nodes_from(remove)\n",
    "    mst = nx.maximum_spanning_tree(G)\n",
    "    \n",
    "    def assign_color(col):\n",
    "      return sector_color_mapping[sp500_sector_mapping[col]]\n",
    "    def assign_color_edge(correlation):\n",
    "      if correlation < 0:\n",
    "        return \"#BF0603\"\n",
    "      else:\n",
    "        return \"#00CC66\"\n",
    "    edge_colors = []\n",
    "    node_colors = []\n",
    "    for key, value in nx.get_edge_attributes(mst, 'weight').items():\n",
    "        edge_colors.append(assign_color_edge(value))\n",
    "    for key, value in dict(mst.degree).items():\n",
    "        node_colors.append(assign_color(key))\n",
    "      \n",
    "    labels = {n:n for n in mst.nodes()}\n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    \n",
    "    tree = nx.fruchterman_reingold_layout(mst, k=0.25).items()\n",
    "    \n",
    "    for node, (x_,y_) in tree:\n",
    "        node_x.append(x_)\n",
    "        node_y.append(y_)\n",
    "        \n",
    "    def get_dim_of_node(name):\n",
    "        for node, (x,y) in tree:\n",
    "            if node == name:\n",
    "                return x,y\n",
    "        \n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    \n",
    "    weights= []\n",
    "    for node1, node2, w in mst.edges(data=True):\n",
    "        x0, y0 = get_dim_of_node(node1)\n",
    "        x1, y1 =  get_dim_of_node(node2)\n",
    "        edge_x.append(x0)\n",
    "        edge_x.append(x1)\n",
    "        edge_x.append(None)\n",
    "        edge_y.append(y0)\n",
    "        edge_y.append(y1)\n",
    "        edge_y.append(None)\n",
    "        weights.append((round(w[\"weight\"],1), (x0+x1)/2, (y0+y1)/2))\n",
    "                              \n",
    "    with network.batch_update():\n",
    "        network.data[1].x = node_x\n",
    "        network.data[1].y = node_y\n",
    "        network.data[1].text = list(labels)\n",
    "        network.data[1].marker.color = node_colors\n",
    "                          \n",
    "        network.data[0].x = edge_x\n",
    "        network.data[0].y = edge_y\n",
    "        network.data[0].text = list(weights)\n",
    "        network.update_layout(xaxis_zeroline=False, yaxis_zeroline=False, xaxis_showgrid=False, yaxis_showgrid=False, plot_bgcolor='rgba(0,0,0,0)')\n",
    "\n",
    "threshold_choice.observe(plot_corr_graph, names=\"value\")\n",
    "widgets.VBox([threshold_choice, network])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.5.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.缺失值可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(df_X.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\n",
    "plt.xlabel(\"Column Number\")\n",
    "plt.ylabel(\"Sample Number\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化每一个特征缺失值的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.isna().mean().sort_values().plot(\n",
    "    kind=\"bar\", figsize=(15, 4),\n",
    "    title=\"Percentage of missing values per feature\",\n",
    "    ylabel=\"Ratio of missing values per feature\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.seaborn多个子图（subplot）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.suptitle('A single ax with no data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多个子图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.suptitle('1 row x 2 columns axes with no data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多子图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, sharex=True, figsize=(16,8))\n",
    "fig.suptitle('3 rows x 4 columns axes with no data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入数据示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_filepath = '../datasets/pokemon.csv'\n",
    "pokemon = pd.read_csv(pokemon_filepath)\n",
    "pokemon.head()\n",
    "\n",
    "poke_num = pokemon[['Name', 'HP', 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed']].set_index('Name')\n",
    "\n",
    "bulbasaur = poke_num.loc['Bulbasaur']\n",
    "charmander = poke_num.loc['Charmander']\n",
    "squirtle = poke_num.loc['Squirtle']\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "fig.suptitle('Pokemon Stats by Generation')\n",
    "\n",
    "sns.boxplot(ax=axes[0, 0], data=pokemon, x='Generation', y='Attack')\n",
    "sns.boxplot(ax=axes[0, 1], data=pokemon, x='Generation', y='Defense')\n",
    "sns.boxplot(ax=axes[0, 2], data=pokemon, x='Generation', y='Speed')\n",
    "sns.boxplot(ax=axes[1, 0], data=pokemon, x='Generation', y='Sp. Atk')\n",
    "sns.boxplot(ax=axes[1, 1], data=pokemon, x='Generation', y='Sp. Def')\n",
    "sns.boxplot(ax=axes[1, 2], data=pokemon, x='Generation', y='HP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给subplot加标题："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax1.title.set_text('First Plot')\n",
    "ax2.title.set_text('Second Plot')\n",
    "ax3.title.set_text('Third Plot')\n",
    "ax4.title.set_text('Fourth Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Correlation-Based Filter (FCBF) selection\n",
    "http://www.public.asu.edu/~huanliu/papers/icml03.pdf\n",
    "\n",
    "https://github.com/shiralkarprashant/FCBF\n",
    "https://github.com/onlinex/FCBF\n",
    "https://github.com/Doctorado-ML/mufs\n",
    "https://github.com/SantiagoEG/FCBF_module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.数组拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "idx = np.concatenate([np.arange(1,12), np.arange(19,20)])\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.5.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.设置随机种子，保证重复性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_state = 42\n",
    "random.seed(random_state)\n",
    "noise = [random.random() for i in range(1,10)]\n",
    "noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.NIR光谱波长点选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A variable selection method based on uninformative variable elimination for\n",
    "multivariate calibration of near-infrared spectra\n",
    "https://www.libpls.net/publication/MCUVE_2008.pdf\n",
    "* https://github.com/JinZhangLab/CalibrationLibrary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.NIR光谱预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Review of the most common pre-processing techniques for near-infrared spectra](http://www.models.life.ku.dk/sites/default/files/preproNIR.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Selection With Boruta Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BorutaShap import BorutaShap\n",
    "\n",
    "# Creates a BorutaShap selector for regression\n",
    "# True for classification; False for Regression\n",
    "selector = BorutaShap(importance_measure = 'shap', classification = True)\n",
    "\n",
    "# Fits the selector\n",
    "X_train = df_train[names_stats]\n",
    "y_train = df_train[target]\n",
    "selector.fit(X = X_train, y = y_train, n_trials = 100, sample = False, verbose = True)\n",
    "\n",
    "# Display features to be removed\n",
    "features_to_remove = selector.features_to_remove\n",
    "print(features_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Classification with correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Classification with correlated features: unreliability of feature\n",
    "ranking and solutions](https://watermark.silverchair.com/btr300.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAt0wggLZBgkqhkiG9w0BBwagggLKMIICxgIBADCCAr8GCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMWTrongKExeaxgkybAgEQgIICkE8lJeGu_NA2wdEqTUf1i47fVzmUSjm_OII4-BnGcKSxHOm6S7dEd1lUDatB-TR_JWnrQmp7c16aPNpByWwpCGWhCQ274EMuF2R_FjmA-dFmuPxShvlskHj4fGQMsIquur7UYT-sLwf5wGKIsXlU1Aro8wBltUzglTMswJw3w0y1AQjvkNo_-bL_lE51QXBxDmlNQbeR89EZuDrFf_8W51ww8unnDYLk4oS4TrEtnGCH0Z_MJFthtyJ3-IFhICbWsCSXQiwADbRX-tb0LOM-6aQFYA6E4lyOonJDPcsQYL53BOv1GyIkW1cU_uqSxKGrpIdCf4SWBBB8GJFP93wYG6_L_oap1qvNmRoQ0wiDWv-3Jb_j1w7m23dbQ46fssciAA5kW69E_IFi9co0QiRuox2rYooozKoRKf3T8SEZMvChWZA9DfcnGa-pfv9MpEXCi8tlgeGOEb6tc6yLTh0Uehi_bFh58GKxS0TwWHYF2I5AkP80vURBiYG1szeBwsh3Q_e-38VsPvaMhCTWpYYSzbPAzExCOyje7hCegnRkJzT7NZwxZQXSUimsD3i0dy8Hx9ADnaFCNfXRmvOeFbz1BXlSzfueYHLjWlCwJQRfruxjNjRe2t35kB1N0gd2vK0o6daVOdfYPh5PXw8cdYOoVn7nRHJ9RnYk0wHNH4e7GSxSgmq-XYarQzd1xxhCzzLsS0RVElJL1S3Zu5HUMjoNqiZllGbWjtRfWUnR7w_K5OL-HzIi9hP563P3l6Xyp2P5xblroPYVoZIrp-mP2VCvMHVMEwjNcQsgEYpyStadnPsq4pD2iMGv8ANTWi9GhidUaVEYkIW8qd3xFLl5z35UFfnwTE4nFGoyO1AO-K57KA80)\n",
    "\n",
    "In this article,\n",
    "we show that the measures of feature relevance corresponding to\n",
    "the above-mentioned methods are biased such that the weights of\n",
    "the features belonging to groups of correlated features decrease\n",
    "as the sizes of the groups increase, which leads to incorrect model\n",
    "interpretation and misleading feature ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.dict转Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bb = {\n",
    "\t\"one\": 'out',\n",
    "\t\"two\": 'in',\n",
    "\t\"three\": 1987,\n",
    "}\n",
    "print(type(bb))\n",
    "aa = pd.Series(bb)\n",
    "print(type(aa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.热力图观察dataframe是否有Null值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NULL Analysis\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "sns.heatmap(dataset.isnull(), cbar=True)\n",
    "plt.title('NULL Values')\n",
    "plt.tight_layout() # Adjust the padding between and around subplots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.beat XGBoost with linear model by feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://medium.com/@dave.cote.msc/demonstrating-the-power-of-feature-engineering-part-ii-how-i-beat-xgboost-with-linear-regression-e63aeb6a15f8\n",
    "* https://github.com/christophM/rulefit\n",
    "* https://github.com/natekupp/ffx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/amueller/word_cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.crosstab可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'.\\data\\banking.csv')\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算'y'中每类的平均值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算'job'中每类的平均值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('job').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.crosstab(data.job,data.y).plot(kind='bar')\n",
    "plt.title('Purchase Frequency for Job Title')\n",
    "plt.xlabel('Job')\n",
    "plt.ylabel('Frequency of Purchase')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单根竖条，总和为1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=pd.crosstab(data.marital,data.y)\n",
    "table.div(table.sum(1).astype(float), axis=0).plot(kind='bar', stacked=True)\n",
    "plt.title('Stacked Bar Chart of Marital Status vs Purchase')\n",
    "plt.xlabel('Marital Status')\n",
    "plt.ylabel('Proportion of Customers')\n",
    "plt.savefig('mariral_vs_pur_stack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.5.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.观察不同类别样本是否均衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = df[target].value_counts()\n",
    "\n",
    "# unique, counts = np.unique(y_train, return_counts=True)\n",
    "# target_counts = dict(zip(unique, counts))\n",
    "\n",
    "for key, val in target_counts.items():\n",
    "    #print(f\"Class : {label_decoder[key]}, Count : {val}\")\n",
    "    print(f\"Class : {key}, Count : {val}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.canvas.draw()\n",
    "#pd.Series(target_counts).plot(kind='bar', title='Sample Count (each class)')\n",
    "target_counts.plot(kind='bar', title='Sample Count (each class)')\n",
    "code_labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "#text_labels = [label_decoder[int(float(item))] for item in code_labels]\n",
    "text_labels = [int(float(item)) for item in code_labels]\n",
    "ax.set_xticklabels(text_labels, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.catplot设置xticklabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_stats_all.loc[saved_spectrum_names, \"stats\"].sort_values(ascending=False)\n",
    "\n",
    "for name in tmp.index:\n",
    "    plot = sns.catplot(x=target, y=name, data=df_train, kind=\"box\")\n",
    "    for axes in plot.axes.flat:\n",
    "        code_labels = [item.get_text() for item in axes.get_xticklabels()]\n",
    "        text_labels = [label_decoder[int(float(item))] for item in code_labels]\n",
    "        axes.set_xticklabels(text_labels, rotation=90)\n",
    "    plt.title(f\"stats:{df_stats_all.loc[name, 'stats']:.3f}, pval:{df_stats_all.loc[name, 'pval']:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.多个模型分类结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "X = X_test[names_X[indices[:2]]]\n",
    "y = y_test\n",
    "\n",
    "# Plotting Decision Regions\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n",
    "                         ['Logistic Regression', 'Random Forest', 'RBF kernel SVM', 'Ensemble'],\n",
    "                         itertools.product([0, 1], repeat=2)):\n",
    "    clf.fit(X, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.载入sklearn iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.5.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.多数投票分类器（MajorityVotingClassifier）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVotingClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.models = list()\n",
    "        \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        if len(self.models) == 0:\n",
    "            raise ValueError('Classifier hasn\\'t any models \"inside\"')\n",
    "        \n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        results = [model.predict([X])[0] for model in self.models]\n",
    "        \n",
    "        map = dict()\n",
    "        \n",
    "        for result in results:\n",
    "            if result in map:\n",
    "                map[result] += 1\n",
    "            else:\n",
    "                map[result] = 1        \n",
    "        \n",
    "        map = list(map.items())\n",
    "        map.sort(reverse=True, key= lambda i : i[1])\n",
    "        return map[0][0]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        predictions = np.array([self.predict(x) for x in X])\n",
    "        \n",
    "        return np.sum(predictions == y) / len(y)\n",
    "    \n",
    "    def score_models(self, X, y):\n",
    "        results = [model.score(X, y) for model in self.models]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mjvclf = MajorityVotingClassifier()\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "mlp = MLPClassifier(activation='tanh', max_iter=10000)\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "mjvclf.add_model(lr)\n",
    "mjvclf.add_model(rf)\n",
    "mjvclf.add_model(mlp)\n",
    "mjvclf.add_model(dt)\n",
    "\n",
    "mjvclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mjvclf.score(X_test, y_test))\n",
    "mjvclf.score_models(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn官方版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import numpy as np\n",
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> from sklearn.naive_bayes import GaussianNB\n",
    ">>> from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    ">>> clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    ">>> clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    ">>> clf3 = GaussianNB()\n",
    ">>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    ">>> y = np.array([1, 1, 1, 2, 2, 2])\n",
    ">>> eclf1 = VotingClassifier(estimators=[\n",
    "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    ">>> eclf1 = eclf1.fit(X, y)\n",
    ">>> print(eclf1.predict(X))\n",
    "[1 1 1 2 2 2]\n",
    ">>> np.array_equal(eclf1.named_estimators_.lr.predict(X),\n",
    "...                eclf1.named_estimators_['lr'].predict(X))\n",
    "True\n",
    ">>> eclf2 = VotingClassifier(estimators=[\n",
    "...         ('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
    "...         voting='soft')\n",
    ">>> eclf2 = eclf2.fit(X, y)\n",
    ">>> print(eclf2.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.5.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.多类别数据可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多类别直方图，加入'hue'标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x=\"flipper_length_mm\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多类别条形图，加入'hue'标签："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = “species”, y = “flipper_length_mm”, \n",
    "            data = data, hue = “sex”)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.聚类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X, y = make_blobs(n_samples=150,\n",
    "                  n_features=2,\n",
    "                  centers=3,\n",
    "                  cluster_std=1.2,\n",
    "                  shuffle=True,\n",
    "                  random_state=random_state)\n",
    "\n",
    "plt.scatter(X[:,0],\n",
    "            X[:,1],\n",
    "            c='red',\n",
    "            marker='o',\n",
    "            s=50)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 聚类建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3,\n",
    "            init='random',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            tol=1e-04,\n",
    "            random_state=random_state)\n",
    "\n",
    "y_km = km.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[y_km==0, 0],\n",
    "            X[y_km==0, 1],\n",
    "            s=50,\n",
    "            c='lightgreen',\n",
    "            marker='s',\n",
    "            label='cluster_1')\n",
    "\n",
    "plt.scatter(X[y_km==1, 0],\n",
    "            X[y_km==1, 1],\n",
    "            s=50,\n",
    "            c='orange',\n",
    "            marker='o',\n",
    "            label='cluster_2')\n",
    "plt.scatter(X[y_km==2, 0],\n",
    "            X[y_km==2, 1],\n",
    "            s=50,\n",
    "            c='lightblue',\n",
    "            marker='v',\n",
    "            label='cluster_3')\n",
    "\n",
    "plt.scatter(km.cluster_centers_[:,0],\n",
    "            km.cluster_centers_[:,1],\n",
    "            s=250,\n",
    "            c='red',\n",
    "            marker='*',\n",
    "            label='centroids')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 结果评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 肘方法\n",
    "簇内误差平方和："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Distortion: {km.inertia_:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于簇内平方和估计最优的簇数量k："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "for i in range(1,11):\n",
    "    km = KMeans(n_clusters=i,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            tol=1e-04,\n",
    "            random_state=random_state)\n",
    "    km.fit(X)\n",
    "    distortions.append(km.inertia_)\n",
    "    \n",
    "plt.plot(range(1,11),distortions,marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 轮廓分析\n",
    "通过图形工具度量簇中样本聚集的密集程度，定量分析聚类质量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3,\n",
    "            init='k-means++',\n",
    "            n_init=10,\n",
    "            max_iter=300,\n",
    "            tol=1e-04,\n",
    "            random_state=random_state)\n",
    "\n",
    "y_km = km.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "轮廓分析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "cluster_labels = np.unique(y_km)\n",
    "n_clusters = cluster_labels.shape[0]\n",
    "\n",
    "silhouette_vals = silhouette_samples(X, y_km, metric='euclidean')\n",
    "\n",
    "y_ax_lower, y_ax_upper = 0, 0\n",
    "yticks = []\n",
    "for i, c in enumerate(cluster_labels):\n",
    "    c_silhouette_vals = silhouette_vals[y_km==c]\n",
    "    y_ax_upper += len(c_silhouette_vals)\n",
    "    \n",
    "    color = matplotlib.cm.jet(i / n_clusters)\n",
    "    \n",
    "    plt.barh(range(y_ax_lower, y_ax_upper),\n",
    "             c_silhouette_vals,\n",
    "             height=1.0,\n",
    "             edgecolor='none',\n",
    "             color=color)\n",
    "    yticks.append((y_ax_lower+y_ax_upper) / 2)\n",
    "    y_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "silhouette_avg = np.mean(silhouette_vals)\n",
    "\n",
    "plt.axvline(silhouette_avg,\n",
    "            color='red',\n",
    "            linestyle='--')\n",
    "plt.yticks(yticks,cluster_labels+1)\n",
    "plt.ylabel('Cluster')\n",
    "plt.xlabel('Silhouette coefficient')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 凝聚层次聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "ac = AgglomerativeClustering(n_clusters=2,\n",
    "                             affinity='euclidean',\n",
    "                             linkage='complete')\n",
    "\n",
    "labels = ac.fit_predict(X)\n",
    "print(f'Cluster labels: {labels}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "样本被划分到两个不同的簇。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN（基于密度的聚类）\n",
    "基于密度空间的聚类算法（Density-based Spatial Clustering of Applications with Noise，DBSCAN），可以识别并移除噪声点。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个半月形的数据集，分别使用前述三个不同的聚类方法，对其聚类结果进行比较："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "random_state=42\n",
    "X, y = make_moons(n_samples=200,\n",
    "                  noise=0.05,\n",
    "                  random_state=random_state)\n",
    "\n",
    "plt.scatter(X[:,0],X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先使用KMeans和层次聚类，看聚类效果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(8,3))\n",
    "\n",
    "km = KMeans(n_clusters=2,\n",
    "            random_state=random_state)\n",
    "\n",
    "y_km = km.fit_predict(X)\n",
    "\n",
    "ax1.scatter(X[y_km==0, 0],\n",
    "            X[y_km==0, 1],\n",
    "            s=50,\n",
    "            c='lightgreen',\n",
    "            marker='s',\n",
    "            label='cluster_1')\n",
    "\n",
    "ax1.scatter(X[y_km==1, 0],\n",
    "            X[y_km==1, 1],\n",
    "            s=50,\n",
    "            c='orange',\n",
    "            marker='o',\n",
    "            label='cluster_2')\n",
    "ax1.set_title('KMeans clustering')\n",
    "\n",
    "ac = AgglomerativeClustering(n_clusters=2,\n",
    "                             affinity='euclidean',\n",
    "                             linkage='complete')\n",
    "\n",
    "y_ac = ac.fit_predict(X)\n",
    "ax2.scatter(X[y_ac==0, 0],\n",
    "            X[y_ac==0, 1],\n",
    "            s=50,\n",
    "            c='lightgreen',\n",
    "            marker='s',\n",
    "            label='cluster_1')\n",
    "\n",
    "ax2.scatter(X[y_ac==1, 0],\n",
    "            X[y_ac==1, 1],\n",
    "            s=50,\n",
    "            c='orange',\n",
    "            marker='o',\n",
    "            label='cluster_2')\n",
    "ax2.set_title('Agglomerative Clustering')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，以上两种聚类方法都无法将复杂形状数据的两个簇分开。\n",
    "\n",
    "下面尝试用DBSCAN："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.2,\n",
    "            min_samples=5,\n",
    "            metric='euclidean')\n",
    "\n",
    "y_db = db.fit_predict(X)\n",
    "\n",
    "plt.scatter(X[y_db==0, 0],\n",
    "            X[y_db==0, 1],\n",
    "            s=50,\n",
    "            c='lightgreen',\n",
    "            marker='s',\n",
    "            label='cluster_1')\n",
    "\n",
    "plt.scatter(X[y_db==1, 0],\n",
    "            X[y_db==1, 1],\n",
    "            s=50,\n",
    "            c='orange',\n",
    "            marker='o',\n",
    "            label='cluster_2')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN可将任意形状的数据进行聚类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sns pairplot\n",
    "https://seaborn.pydata.org/generated/seaborn.pairplot.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"penguins\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species', corner=True)\n",
    "#sns.pairplot(df, hue=\"species\", markers=[\"o\", \"s\", \"D\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue=\"species\", diag_kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, kind='reg', corner=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "仅选择部分变量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    df,\n",
    "    x_vars=[\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\"],\n",
    "    y_vars=[\"bill_length_mm\", \"bill_depth_mm\"],\n",
    "    hue='species', \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.05.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.从map中或者指定value对应的key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_decoder = {\n",
    "    1:\"四川会东B1F-B云87第一批次\",\n",
    "    2:\"四川会东B1F-B红大第一批次\",\n",
    "    3:\"四川会东B1F云87-A\",\n",
    "    4:\"四川会东B1F红大-A\",\n",
    "    5:\"四川会东B2F-A红大第一批次\",\n",
    "    6:\"四川会东B2F-B云87散第一批次\",\n",
    "    7:\"四川会东B2F-B红大第一批次\",\n",
    "    8:\"四川会东B2F云87-A\",\n",
    "    9:\"四川会东B2F红大-A\",\n",
    "    10:\"四川会东B3F-B红大\",\n",
    "    11:\"四川会东B3F云87-A\",\n",
    "    12:\"四川会东C1F云87\",\n",
    "    13:\"四川会东C1F云87-A\",\n",
    "    14:\"四川会东C1F红大\",\n",
    "    15:\"四川会东C2F云87-A\",\n",
    "    16:\"四川会东C2F红大-A\",\n",
    "    17:\"四川会东C3F云87-A\",\n",
    "    18:\"四川会东C3F红大-A\",\n",
    "    19:\"四川会东红大B3F-A\",\n",
    "    20:\"四川会理C1F-B红大第一批次\",\n",
    "    21:\"四川会理C1F云87-A\",\n",
    "    22:\"四川会理C1F红大\",\n",
    "    23:\"四川会理C3F-B红大第一批次\",\n",
    "    24:\"四川会理C3F红大-A\",\n",
    "    25:\"四川德昌B2F-B红大\",\n",
    "    26:\"四川德昌B2F红大-A\",\n",
    "    27:\"四川德昌B3F红大-A\",\n",
    "    28:\"四川德昌C2F-A红大第一批次\",\n",
    "    29:\"四川德昌C2F-B红大第一批次\",\n",
    "    30:\"四川德昌C3F-A红大\",\n",
    "    31:\"四川德昌C4F-B红大第一批次\",\n",
    "    32:\"四川德昌C4F红大-A\",\n",
    "    33:\"四川德昌宁南C1F-B云87第一批次\",\n",
    "    34:\"四川德昌宁南C1F云87-A\",\n",
    "    35:\"四川德昌宁南C2F-B云87第一批次\",\n",
    "    36:\"四川德昌宁南C2F云87-A\",\n",
    "    37:\"四川德昌普格B2F-A云87\",\n",
    "    38:\"四川德昌普格B2F-B云87\",\n",
    "    39:\"四川德昌普格C2F-B云87第一批次\",\n",
    "    40:\"四川德昌普格C2F云87-A\",\n",
    "    41:\"四川德昌普格C3F-A云87\",\n",
    "    42:\"四川德昌普格C3F-B云87\",\n",
    "    43:\"四川德昌普格C4F-A云87\",\n",
    "    44:\"四川德昌盐源B3F云87-A\",\n",
    "    45:\"四川德昌盐源C2F-B云87第一批次\",\n",
    "    46:\"四川德昌盐源C2F云87-A\",\n",
    "    47:\"四川德昌盐源C3F云87-A\",\n",
    "    48:\"四川德昌西昌B1F云87-A\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc2f_batch = ['四川德昌B2F红大-A','四川德昌普格B2F-A云87','四川会东B2F-A红大第一批次',\n",
    "              '四川会东B2F红大-A','四川会东B2F云87-A','四川德昌C2F-A红大第一批次',\n",
    "              '四川德昌宁南C2F云87-A','四川德昌普格C2F云87-A','四川德昌盐源C2F云87-A',\n",
    "              '四川会东C2F红大-A','四川会东C2F云87-A']\n",
    "\n",
    "bc3f_batch = ['四川德昌B3F红大-A','四川德昌盐源B3F云87-A','四川会东B3F-B红大',\n",
    "              '四川会东B3F云87-A','四川会东红大B3F-A','四川德昌C3F-A红大',\n",
    "              '四川德昌普格C3F-A云87','四川会东C3F红大-A','四川会东C3F云87-A',\n",
    "              '四川德昌盐源C3F云87-A','四川会理C3F红大-A']\n",
    "\n",
    "bc4f_batch = ['四川德昌C4F红大-A','四川德昌普格C4F-A云87']\n",
    "\n",
    "labels_encoder =  {v : k for k, v in labels_decoder.items()}\n",
    "bc2f_batch_num = [labels_encoder[v] for v in bc2f_batch]\n",
    "bc3f_batch_num = [labels_encoder[v] for v in bc3f_batch]\n",
    "bc4f_batch_num = [labels_encoder[v] for v in bc4f_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_encoder =  {v : k for k, v in labels_decoder.items()}\n",
    "bc2f_batch_num = [labels_encoder[v] for v in bc2f_batch]\n",
    "bc3f_batch_num = [labels_encoder[v] for v in bc3f_batch]\n",
    "bc4f_batch_num = [labels_encoder[v] for v in bc4f_batch]\n",
    "\n",
    "print(bc2f_batch_num)\n",
    "print(bc3f_batch_num)\n",
    "print(bc4f_batch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.07.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.StratifiedGroupKFold 分层分组交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "\n",
    "X = np.ones((17, 2))\n",
    "y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=3)\n",
    "for train_idxs, test_idxs in cv.split(X, y, groups):\n",
    "    print(\"TRAIN:\", groups[train_idxs])\n",
    "    print(\"      \", y[train_idxs])\n",
    "    print(\" TEST:\", groups[test_idxs])\n",
    "    print(\"      \", y[test_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.08.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numpy本地持久化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储到本地："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('xx', X)\n",
    "\n",
    "with open('xx.npy', 'wb') as f:\n",
    "    np.save(f, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取本地数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xx.npy', 'rb') as f:\n",
    "    a = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.08.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实际与模拟转换关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "plt.rcParams[\"figure.max_open_warning\"] = 100\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rc(\"font\", family=\"MicroSoft YaHei\")\n",
    "\n",
    "X = np.array([305.278, 227.087, 378.159, 230.403, 230.935, 227.742]).astype(float)\n",
    "X = X.reshape(-1, 1)\n",
    "y = np.array([40, 30, 50, 30, 30, 30]).astype(float)\n",
    "y= y.reshape(-1, 1)\n",
    "\n",
    "mdl = LinearRegression(fit_intercept=False).fit(\n",
    "    X, y\n",
    ")\n",
    "x = np.linspace(200, 400, 40).reshape(-1, 1)\n",
    "y_hat = mdl.predict(X)\n",
    "\n",
    "k = mdl.coef_[0]\n",
    "\n",
    "df_X = pd.DataFrame(data=X, index=[1,2,3,4,5,6])\n",
    "df_y = pd.DataFrame(data=y, index=[1,2,3,4,5,6])\n",
    "corr_res = pd.concat([df_X, df_y], axis=1).corr().to_numpy()\n",
    "# coef = np.corrcoef(X, y)\n",
    "# print(k)\n",
    "print(corr_res)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X, y, \"*\")\n",
    "plt.plot(X, y_hat, \"--\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"X：检测长度（像素）\")\n",
    "plt.ylabel(\"y：实际长度（毫米）\")\n",
    "#plt.title(f\"拟合方程：\\n y = {k} * x\")\n",
    "plt.title(f\"相关系数：{corr_res[1, 0]:.4f}\\n y = {k} * x\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "xx = np.random.rand(4)\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "url = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/11848/862157/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1662645274&Signature=In%2FEX1dpkUPdhPOoeySpUZP%2FjqocS%2FPKVazyUH%2BKrjdWmqfnYrLJTMmXMyf7%2F3w4RHEctzDWPz5XodgFodBy7IFdIP7eGIc39US0zZcDm47pkgMGyOZ6xEoboQn1JGyktvM0lvit54Rbnm1ijJOhFUmvaK96luGJLNGRgNZz%2FPS5vd0kDZC89bZgmPFPK08zsvMtWDlsy2XY0zoDgKdisXQLDa18TZhwcJiNbAXsGw5%2BmLdOeAjLs%2BQMWnyXhQ%2FvuDgSTXaoJHbJ94K6i0eMTWSjiniG0sqeQJTTFXmqNaNXiBFY4UWK7AN7R7hY8SMEOqK3xieM%2Btn7stL%2BNE9nzA%3D%3D&response-content-disposition=attachment%3B+filename%3Dhistopathologic-cancer-detection.zip\"\n",
    "\n",
    "outfile_name = \"histopathologic-cancer-detection.zip\"\n",
    "desdir = \"F:\\\\数据存储\\\\KaggleDataSet\"\n",
    "des_file = os.path.join(desdir, outfile_name)\n",
    "\n",
    "wget.download(url, des_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.09.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "B_ary = np.array([0.6042, 0.2421, 0.146, 0.0078])\n",
    "H_ary = np.array([0.5671, 0.2775, 0.1469, 0.0085])\n",
    "\n",
    "\n",
    "bh_mix_ins = np.array([0.56, 0.2793, 0.1515, 0.0093])\n",
    "after_mix = np.array([0.5467, 0.2904, 0.1543, 0.0086])\n",
    "\n",
    "bh_mix_cal = B_ary * 0.63 + H_ary * 0.27\n",
    "tmp = bh_mix_ins - bh_mix_cal\n",
    "print(tmp*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.09.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.骨架提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import rescale_intensity\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mahotas as mt\n",
    "\n",
    "def cv_imread(file_path,color_patten=cv2.IMREAD_COLOR):\n",
    "    \"\"\"\n",
    "    读取中文路径图片\n",
    "    :ctime: 2022.06.20\n",
    "    :param file_path:图片目录\n",
    "    :param color_patten: 图片模式\n",
    "    :return: 对应模式下的图片矩阵\n",
    "    \"\"\"\n",
    "    cv_img = cv2.imdecode(np.fromfile(file_path,dtype=np.uint8),color_patten)\n",
    "    return cv_img\n",
    "\n",
    "\n",
    "def plt_imshow(image, figszie=(15,7)):\n",
    "    plt.figure(figsize=figszie)\n",
    "    if len(image.shape) == 3: # 彩色图，三维数据\n",
    "        plt.imshow(image)\n",
    "    elif len(image.shape) == 2: # 灰度图，一维数据\n",
    "        plt.imshow(image,cmap='gray')\n",
    "    else:\n",
    "        assert('wrong image dims!')\n",
    "        return\n",
    "\n",
    "def bwmorphClean(image):\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    pad = 1\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad, cv2.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW), dtype=\"float32\")\n",
    "\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\n",
    "            if roi[0,0] == roi[1,0] == roi [2,0] == roi [0,1] == roi [0,2] == roi [1,2] == roi [2,1] == roi [2,2] == 0:\n",
    "                output[y - pad, x - pad] = 0\n",
    "            else:\n",
    "                output[y - pad, x - pad] = roi[1,1]\n",
    "\n",
    "    output = rescale_intensity(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    "\n",
    "    return output\n",
    "\n",
    "def main():\n",
    "    img_path = r'F:/数据存储/上烟卷接制丝/烟丝综合测试台图像采集/烟丝检测图像_220118/001.bmp'\n",
    "\n",
    "    img_grey = cv2.cvtColor(cv_imread(img_path), cv2.COLOR_RGB2GRAY)\n",
    "    img_bin = cv2.inRange(img_grey, 5, 180)\n",
    "\n",
    "    totalLabels, label_ids, values, centroid = cv2.connectedComponentsWithStats(img_bin, 4, cv2.CV_32S)\n",
    "    \n",
    "    for ii in range(0, totalLabels):\n",
    "        img_out = np.zeros(img_bin.shape, dtype=\"uint8\")\n",
    "        componentMask = (label_ids == ii).astype(\"uint8\") * 255\n",
    "        img_out = cv2.bitwise_or(img_out, componentMask)\n",
    "\n",
    "        #img_res = bwmorphClean(img_out)\n",
    "        img_res = mt.thin(img_out)\n",
    "        plt_imshow(img_res)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.09.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. np.where\n",
    "\n",
    "numpy.where的几种用法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、numpy广播机制，根据条件对数组进行相应赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "a = np.arange(9).reshape((3, 3))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(a < 4, -1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据条件`a < 4`则将数组对应元素替换为-1， 否则替换为100。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、numpy广播机制，根据多个条件对数组进行相应赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where((a > 2) & (a < 6), -1, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、替换数组满足相应条件的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(a < 4, -1, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(a < 4, a, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：np.where()返回新的数组，原始数组不发生改变。\n",
    "\n",
    "而要改变原始数组，则用法为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a < 4] = -1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4、控制满足条件的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(a < 4, a * 10, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始数组满足条件的赋值为x(a*10)，否则赋值为y(a)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.09.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.多个元素类型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = 1.89\n",
    "rr = 2.08\n",
    "\n",
    "cc = (gg, rr)\n",
    "print(cc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.10.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.wget下载kaggle数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "\n",
    "url = \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/38992/4381753/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1666107008&Signature=lNp6y9Mi%2B7c3c9HgT4iA8NS7yw%2BLq1JsfggsltVnppsz2Bz2tmx28eJJL%2FgJl3azVatnKYb6kIt8k%2BLDCS06WD4WapnYzm%2FY9S0jpKbWeLrMjoWJj1y2Mw3l1wWDKiLdm7X1qWQ8YDD8CTXFBEp5I1oUxQzdx6SDegxM6WUt5C%2F6GI%2B%2Fv9dUJ56kSYXo6NFGh83TZVabj9yFzpCkfZfM3Bb0Y7uEfsZV9AEDQPqtKJQqbRx9FvAZdLxRHeTEfLnnZqsV1yXTfi%2Fjx0OWM04eJ8yin6Gi2UUH1UBalLK1n7wFg7%2F07d6ijEMOdrKJ3%2F%2BpgOxd6gjpCmlowqbrkHtBJw%3D%3D&response-content-disposition=attachment%3B+filename%3Dnfl-big-data-bowl-2023.zip\"\n",
    "outfile_name = \"nfl-big-data-bowl-2023.zip\"\n",
    "desdir = \"F:\\\\opensource\\\\datasets\\\\\\KaggleDataSet\"\n",
    "des_file = os.path.join(desdir, outfile_name)\n",
    "\n",
    "\n",
    "wget.download(url, des_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def copy_dir(src_dir, des_dir):\n",
    "    \"\"\"\n",
    "    :describe: 文件目录拷贝\n",
    "    :author: anrui\n",
    "    :date: 2022.09.24\n",
    "    :param src_dir: 原始目录\n",
    "    :param des_dir: 目标目录\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if os.path.exists(des_dir):\n",
    "        print(\"目标文件目录已存在，先删除\")\n",
    "        shutil.rmtree(des_dir)\n",
    "    print(\"拷贝文件开始...\")\n",
    "    shutil.copytree(src_dir, des_dir)\n",
    "    print(\"拷贝文件结束...\")\n",
    "\n",
    "def extract_dir(root_dir, des_dir):\n",
    "    for f1 in os.listdir(root_dir): # 工序点名称\n",
    "        subdir = os.path.join(root_dir, f1)\n",
    "        for f2 in os.listdir(subdir):\n",
    "            if f2 != \"光谱采集数据\":\n",
    "                continue\n",
    "            subsubdir = os.path.join(subdir, f2)\n",
    "            for f3 in os.listdir(subsubdir):\n",
    "                if f3 != \"检测光谱\":\n",
    "                    continue\n",
    "                subsubsubdir = os.path.join(subsubdir, f3)\n",
    "                for f4 in os.listdir(subsubsubdir):\n",
    "                    if f4 != \"正常光谱\":\n",
    "                        continue\n",
    "                    ob_dir = os.path.join(subsubsubdir, f4)\n",
    "\n",
    "                    # 将光谱取样文件目录拷贝到工序名称目录下\n",
    "                    copy_dir(ob_dir, os.path.join(des_dir, f1))\n",
    "\n",
    "def main():\n",
    "    root_dir = r\"\"\n",
    "    des_dir = r\"\"\n",
    "    extract_dir(root_dir, des_dir)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022.12.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.使用Boneh将notebook编程dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入依赖库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import pandas_bokeh\n",
    "# Embedding plots in Jupyter/Colab Notebook\n",
    "pandas_bokeh.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as HTML\n",
    "# output_file('iris.html', title='iris classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('tips')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e42634819b8c191a5d07eaf23810ff32516dd8d3875f28ec3e488928fbd3c187"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
